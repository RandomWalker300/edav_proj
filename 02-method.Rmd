# Methods

## Data sources
(We describe our data sources, our methods in this chapter)

Storm tracks data can be downloaded from [National Hurricane Center and Central Pacific Hurricane Center](https://www.nhc.noaa.gov/data/#hurdat). The data using in the project is known as Atlantic hurricane database ([HURDAT2](https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-atlantic.pdf)) 1851-2018 ([5.9MB download](https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2018-051019.txt)). The data has a comma-delimited, text format with six-hourly information on the location, maximum winds, central pressure, and (beginning in 2004) size of all known tropical cyclones and subtropical cyclones.

## Data transformat

Describe the process of getting the data into a form in which you could work with it in R.

```{r include=FALSE}
 # keep this chunk in your .Rmd file
 knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
library(stringr)
# Read in data set
#dfile <- read_lines("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2018-051019.txt")
dfile<- "data/hurdat2-1851-2018-051019.txt"
storm_strings <- read_lines(dfile)
```

```{r}

# Identify the header lines that have three commas
library(stringr)
header_locations <- (1:length(storm_strings))[str_count(storm_strings, "\\,") == 3] # count # of strings for each line, the header line has only 3 strings.

headers <- as.list(storm_strings[header_locations])
headers_df <- 
  headers %>%
  purrr::map(stringr::str_sub, start = 1L, end = -2L) %>% # to remove trailing comma
  purrr::map(paste0, "\n") %>%                 # and replace final comma with \n
  purrr::map_dfr(read_csv, col_names = c("id", "name", "n_obs")) %>%
  dplyr::mutate(#name = dplyr::recode(name, "UNNAMED" = id), 
                skip = header_locations) %>%
  dplyr::select(id, name, skip, n_obs)
```

```{r}
# Set data frames names
df_names <- c(
  "date", "time", "record_type", "status", "lat", "long", "wind", "pressure",
  "extent_34_NE", "extent_34_SE", "extent_34_SW", "extent_34_NW",
  "extent_50_NE", "extent_50_SE", "extent_50_SW", "extent_50_NW",
  "extent_64_NE", "extent_64_SE", "extent_64_SW", "extent_64_NW", "nas"
)

storm_dfs <- vector("list", nrow(headers_df))
names(storm_dfs) <- headers_df$id
```

```{r}
# Read in the sub-datasets as data frames
for (i in seq_along(headers_df$name)) {
  storm_dfs[[i]] <- read_csv(dfile,
    skip = headers_df$skip[i],
    n_max = headers_df$n_obs[i],
    col_names = df_names,
    na = c("", "-99", "-999"),
    col_types = list(
      time = col_character(),
      pressure = col_integer(),
      extent_34_NE = col_integer(),
      extent_34_SE = col_integer(),
      extent_34_SW = col_integer(),
      extent_34_NW = col_integer(),
      extent_50_NE = col_integer(),
      extent_50_SE = col_integer(),
      extent_50_SW = col_integer(),
      extent_50_NW = col_integer(),
      extent_64_NE = col_integer(),
      extent_64_SE = col_integer(),
      extent_64_SW = col_integer(),
      extent_64_NW = col_integer()
    )
  )
}
```

```{r}
# Combine and clean the data sets
library(lubridate)
storms <- 
  storm_dfs %>%
  dplyr::bind_rows(.id = "id") %>%
  dplyr::mutate(
    date = lubridate::ymd(date),
    year = lubridate::year(date),
    month = lubridate::month(date),
    day = lubridate::day(date),
    hour = as.numeric(stringr::str_sub(time, 1, 2)),
    datetime = ISOdate(year, month, day, hour, min = 0, sec = 0, tz = "GMT"),
    lat_hemisphere = stringr::str_sub(lat, -1),
    lat_sign = dplyr::if_else(lat_hemisphere == "N", 1, -1),
    lat = as.numeric(stringr::str_sub(lat, 1, -2)) * lat_sign,
    long_hemisphere = stringr::str_sub(long, -1),
    long_sign = dplyr::if_else(long_hemisphere == "E", 1, -1),
    long = as.numeric(stringr::str_sub(long, 1, -2)) * long_sign,
    category = cut(wind, #cut divides the range of x into intervals
      breaks = c(0, 34, 64, 83, 96, 113, 137, 500),
      labels = c(-1, 0, 1, 2, 3, 4, 5),
      include.lowest = TRUE, ordered = TRUE
    ),
    # wind = wind * 1.15078, # transforms knots to mph,
    TSradius1 = extent_34_NE + extent_34_SW,
    TSradius2 = extent_34_NW + extent_34_SE,
    ts_diameter = pmax(TSradius1, TSradius2) * 1.15078, # to convert from nautical miles to miles # pmax: returns the parallel maxima and minima of the input values
    HUradius1 = extent_64_NE + extent_64_SW,
    HUradius2 = extent_64_NW + extent_64_SE,
    hu_diameter = pmax(HUradius1, HUradius2) * 1.15078, # to convert from nautical miles to miles
    status = recode(status,
                    "TD" = "tropical depression",
                    "TS" = "tropical storm", 
                    "HU" = "tropical hurricane", 
                    "EX" = "Extratropical cyclone", ##
                    "SD" = "subtropical depression",
                    "SS" = "subtropical storm", 
                    "HU" = "tropical hurricane", 
                    "LO" = "a low",
                    "WV" = "tropical wave",
                    "DB" = "disturbance")
  ) 
```

```{r}
# data output
headers_df_selected <- headers_df %>% select(c("id","name"))
# headers_df_selected
storms_with_name <- left_join(headers_df_selected, storms, by=c("id")) %>% 
  select(id, name, datetime, year, month, day, hour, lat, long, status, category,
         wind, pressure, 
         extent_34_NE, extent_34_SW, extent_34_NW, extent_34_SE,
         extent_50_NE, extent_50_SW, extent_50_NW, extent_50_SE,
         extent_64_NE, extent_64_SW, extent_64_NW, extent_64_SE,
         ts_diameter, hu_diameter)
```

```{r}
storms_all <- storms_with_name %>% 
  mutate(name= dplyr::if_else(grepl("UNNAMED", name), name,
                              stringr::str_to_title(name)))
```

```{r}
storms_all$status <- factor(storms_all$status)
storms_all$id <- factor(storms_all$id)
storms_all$name <- factor(storms_all$name)
```


```{r}
levels(storms_all$status)
storms_all %>% filter(status == "ET")
```

*Note: there is an "ET" in _Status of system_, however, there is no description in  [HURDAT2](https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-atlantic.pdf), which is a typo in the dataset, `recode` it into 'EX".*


```{r}
storms_all$status <- dplyr::recode(storms_all$status, ET = "Extratropical cyclone")
#levels(factor(storms_all$status))
```


**Narrow to storms that have complete pressure record**

```{r}
# Narrow to storms that have complete pressure record
completeish <- storms_all %>%
  dplyr::group_by(id) %>%
  dplyr::summarise(n_pressure = sum(!is.na(pressure)), p_pressure = mean(!is.na(pressure))) %>%
  dplyr::filter(p_pressure == 1) %>%
  .[["id"]]
#length(completeish)
dim(storms_all)[1]
```

Theare are `r length(completeish)` out of `r dim(storms_all)[1]`storms that have complete pressure record.

```{r}
storms_completish_selected <- storms_all %>%
  filter(
    status %in% c("hurricane", "tropical storm", "tropical depression"),
    id %in% completeish)
```

```{r}
storms_all_add_com <- storms_all %>% mutate(completeish = if_else(status %in% c("hurricane", "tropical storm", "tropical depression") & id %in% completeish, "yes","no"))
storms_all_add_com$completeish <- factor(storms_all_add_com$completeish)
```

**Save tranformed data**

```{r}
dir <- 'data/'
write_csv(storms_all_add_com, file.path(dir, "storms_all_out.csv"))
```

```{r}
dir <- 'data/'
write_csv(storms, file.path(dir, "storms_completish_selected.csv"))
```


## Missing values

Describe any patterns you discover in missing values.


