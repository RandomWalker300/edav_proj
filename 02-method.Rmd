# Methods

## Data sources
(We describe our data sources, our methods in this chapter)

Storm tracks data can be downloaded from [National Hurricane Center and Central Pacific Hurricane Center](https://www.nhc.noaa.gov/data/#hurdat). The data using in the project is known as Atlantic hurricane database ([HURDAT2](https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-atlantic.pdf)) 1851-2018 ([5.9MB download](https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2018-051019.txt)). The data has a comma-delimited, text format with six-hourly information on the location, maximum winds, central pressure, and (beginning in 2004) size of all known tropical cyclones and subtropical cyclones.

## Data transformat

(Describe the process of getting the data into a form in which you could work with it in R.)

```{r include=FALSE}
 # keep this chunk in your .Rmd file
 knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

** load libraries **

```{r}
library(tidyverse)
library(stringr)
# Read in data set
#dfile <- read_lines("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2018-051019.txt")
dfile<- "data/hurdat2-1851-2018-051019.txt"
hurdat2_in <- read_lines(dfile)
```

The dataset is a combination of serveral subsets. Eeach subset is for a storm track record which incluedes header information and values.

_For instance, the header has the following format:_

AL162018,              OSCAR,     36,
* AL – Basin – Atlantic
* 16 – ATCF cyclone number for that year
* 2018 – Year
* OSCAR – Name, if available, or else “UNNAMED” 
* 36  – Number of best track entries – rows – to follow

_The header is followed by data, which has the following format:_

20181026, 1800,  , SS, 25.4N,  45.3W,  35, 1006,   80,   80,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,

* 2018 – Year
* 10  – Month
* 26  – Day
* 09  – Hours in UTC (Universal Time Coordinate) 35 (Spaces 13-14, before 2nd comma) – Minutes
...

**please refer [this file]("https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-atlantic.pdf") for detail information.**

```{r}
header_locations <- (1:length(hurdat2_in))[str_count(hurdat2_in, "\\,") == 3]
header_df <-readr::read_csv(hurdat2_in[header_locations], 
                             col_names = FALSE) %>% 
  dplyr::select(-c("X4"))
names(header_df) <- c("id","name","n_entries")
```

```{r}
# read hearder information
library(stringr)
header_locations <- (1:length(hurdat2_in))[stringr::str_count(hurdat2_in, "\\,") == 3]

header_df <- readr::read_csv(hurdat2_in[header_locations], 
                             col_names = FALSE) %>% 
  dplyr::select(-c("X4"))

names(header_df) <- c("id","name","n_entries")

header_df <-  header_df %>% mutate(header_loc = as.numeric(header_locations))

#tail(header_df)
```



```{r}
# read data value

hurdat2_df <- vector("list", nrow(header_df))
names(hurdat2_df) <- header_df$id
df_names <- c(
  "date", "time", "record_identifier", "status", "latitude", "longitude", "max_wind", "min_pressure",
  "extent_34_NE", "extent_34_SE", "extent_34_SW", "extent_34_NW",
  "extent_50_NE", "extent_50_SE", "extent_50_SW", "extent_50_NW",
  "extent_64_NE", "extent_64_SE", "extent_64_SW", "extent_64_NW", "nas"
)

#
for (i in seq_along(header_df$id)) {
  hurdat2_df[[i]] <- read_csv(dfile,
    skip = header_df$header_loc[i],
    n_max = header_df$n_entries[i],
    col_names = df_names,
    na = c("", "-99", "-999"),
    col_types = list(
      time = col_character(),
      min_pressure = col_integer(),
      extent_34_NE = col_integer(),
      extent_34_SE = col_integer(),
      extent_34_SW = col_integer(),
      extent_34_NW = col_integer(),
      extent_50_NE = col_integer(),
      extent_50_SE = col_integer(),
      extent_50_SW = col_integer(),
      extent_50_NW = col_integer(),
      extent_64_NE = col_integer(),
      extent_64_SE = col_integer(),
      extent_64_SW = col_integer(),
      extent_64_NW = col_integer()
    )
  )
}
```
```{r}
#head(hurdat2_df)
```

```{r}
# Combine and clean the data sets
library(lubridate)
hurdat2 <- 
  hurdat2_df %>%
  dplyr::bind_rows(.id = "id") %>%
  dplyr::mutate(
    date = lubridate::ymd(date),
    year = lubridate::year(date),
    month = lubridate::month(date),
    day = lubridate::day(date),
    hour = as.numeric(stringr::str_sub(time, 1, 2)),
    datetime = as.Date(ISOdate(year, month, day, hour, min = 0, sec = 0, tz = "GMT")),
    #lat_hemisphere = stringr::str_sub(latitude, -1),
    latitude = dplyr::if_else(stringr::str_sub(latitude, -1) == "N",
                              as.numeric(stringr::str_sub(latitude, 1, -2))*1, 
                              as.numeric(stringr::str_sub(latitude, 1, -2))*(-1)),
    longitude = dplyr::if_else(stringr::str_sub(longitude, -1) == "E",
                              as.numeric(stringr::str_sub(longitude, 1, -2))*1, 
                              as.numeric(stringr::str_sub(longitude, 1, -2))*(-1)),
    category = cut(max_wind, # Saffir-Simpson Hurricane Wind Scale
      breaks = c(0, 34, 64, 83, 96, 113, 137, 500),
      labels = c(-1, 0, 1, 2, 3, 4, 5),
      include.lowest = TRUE, ordered = TRUE
    ),
    # wind = wind * 1.15078, # transforms knots to mph,
    TSradius1 = extent_34_NE + extent_34_SW,
    TSradius2 = extent_34_NW + extent_34_SE,
    ts_diameter = pmax(TSradius1, TSradius2) * 1.15078, # to convert from nautical miles to miles # pmax: returns the parallel maxima and minima of the input values
    HUradius1 = extent_64_NE + extent_64_SW,
    HUradius2 = extent_64_NW + extent_64_SE,
    hu_diameter = pmax(HUradius1, HUradius2) * 1.15078, # to convert from nautical miles to miles # pmax: returns the parallel maxima and minima of the input values
    status = recode(status,
                    "TD" = "tropical depression",
                    "TS" = "tropical storm", 
                    "HU" = "tropical hurricane", 
                    "EX" = "Extratropical cyclone", ##
                    "SD" = "subtropical depression",
                    "SS" = "subtropical storm", 
                    "HU" = "tropical hurricane", 
                    "LO" = "a low",
                    "WV" = "tropical wave",
                    "DB" = "disturbance")
  ) 
```

_Note_: category has been calculated based on [Saffir-Simpson Hurricane Wind Scale](https://www.nhc.noaa.gov/aboutsshws.php) to indicate "Types of Damage Due to Hurricane Winds". 

```{r}
# absorb header information to data values
header_df_selected <- header_df %>% select(c("id","name"))
# headers_df_selected
hurdat2_add_name <- left_join(header_df_selected, hurdat2, by=c("id")) %>% 
  select(id, name, datetime, year, month, day, hour, latitude, longitude, status, category,
         max_wind, min_pressure, ts_diameter, hu_diameter)
```

```{r}
hurdat2_out <- hurdat2_add_name %>% 
  mutate(name= dplyr::if_else(grepl("UNNAMED", name), name,
                              stringr::str_to_title(name)))
hurdat2_out$status <- factor(hurdat2_out$status)
hurdat2_out$category <- factor(hurdat2_out$category)
```

```{r}
levels(hurdat2_out$status)
hurdat2_out %>% filter(status == "ET")
```

*Note: there is an "ET" in _Status of system_, which does not included in the description [HURDAT2](https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-atlantic.pdf). This is a typo in the dataset, `recode` it into 'EX".*

```{r}
hurdat2_out$status <- dplyr::recode(hurdat2_out$status, ET = "Extratropical cyclone")
```


** Mark storms that have complete pressure record**

```{r}
completeish <- hurdat2_out %>%
  dplyr::group_by(id) %>%
  dplyr::summarise(n_pressure = sum(!is.na(min_pressure)), p_pressure = mean(!is.na(min_pressure))) %>%
  dplyr::filter(p_pressure == 1) %>%
  .[["id"]]
#length(completeish)
#dim(hurdat2_out)[1]
```

Theare are `r length(completeish)` out of `r dim(hurdat2_out)[1]`storms that have complete pressure record.

```{r}
storms_completish_selected <- hurdat2_out %>%
  filter(
    status %in% c("hurricane", "tropical storm", "tropical depression"),
    id %in% completeish)
```

```{r}
hurdat2_out_add_com <- hurdat2_out %>% mutate(completeish = if_else(status %in% c("hurricane", "tropical storm", "tropical depression") & id %in% completeish, "yes","no"))
hurdat2_out_add_com$completeish <- factor(hurdat2_out_add_com$completeish)
```

**Meaning for each variables**

```{r}
names(hurdat2_out_add_com)
```
**_id_**

Storm id, which is unique. A id is a combination of 8 characters, for example, 'AL092011', 
* AL (Spaces 1 and 2) – Basin – Atlantic
* 09 (Spaces 3 and 4) – ATCF cyclone number for that year
* 2011 (Spaces 5-8, before first comma) – Year
for detail information, please see [dataformat](https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-atlantic.pdf)

**_name_**

Storm Name, which is non-unique. There are six lists that are used in rotation and re-cycled every six years, i.e., the 2013 list is used again in 2019. For more information, please see [tropical cyclone names](https://www.nhc.noaa.gov/aboutnames.shtml).

**_datetime, year, month, day, hour_**

Date of report (in Universal Time Coordinate)

**_latitude,longitude_**

Location of storm center

**_status_**

Storm classification (Tropical Depression, Tropical Storm, or Hurricane)

**_category_**

[Saffir-Simpson storm category](https://www.nhc.noaa.gov/aboutsshws.php) (estimated from wind speed. -1 = Tropical Depression, 0 = Tropical Storm)

**_max_wind_**

storm's maximum sustained wind speed (in knots)

**_min_pressure_**

Air pressure at the storm's center (in millibars)

**_ts_diameter_**

Diameter of the area experiencing tropical storm strength winds (34 knots or above)

**_hu_diameter_**

Diameter of the area experiencing hurricane strength winds (64 knots or above)

**_completeish_**

whether storms that have complete pressure record, yes or no


**Save transformed data** for further use.

```{r}
dir <- 'data/'
write_csv(hurdat2_out_add_com, file.path(dir, "hurdat2_out.csv"))
```

## Missing values

Describe any patterns you discover in missing values.


